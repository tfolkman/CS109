{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#BIAS\n",
      "* Selection Bias\n",
      "    * Picking and choosing some portion of the data\n",
      "    * Publication Bias is a type of this bias\n",
      "        * Journals sometimes won't publish non-significant articles, so biases towards significance\n",
      "* Censoring Bias\n",
      "    * Not able to observe some of the data; e.g. survival time for people with a disease (some people might not die before analyze data).\n",
      "* Length Bias\n",
      "    * See models notes\n",
      "* Sampling Bias\n",
      "    * Some ways of sampling from a population can introduce bias. It is very important to think about where the data are coming from and if anything is excluded"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#P-Value\n",
      "The further out the test\n",
      "statistic is in the tail, the smaller the **P-value**, and the stronger the evidence against the null\n",
      "hypothesis in favor of the alternative. The p-value is closely related to the sample size: with a big enough sample size, everything becomes significant. We care more about **scientific significance** - does it actually matter?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Sampling\n",
      "* Simple Random Sampling\n",
      "    * Just take a completely random sample from population. Not always possible and can be inefficient if very heterogenous group\n",
      "* Stratified Sampling\n",
      "    * Good if population broken up into groups (e.g. gender, age, etc.); take a certain number from each group for sample\n",
      "* Cluster Sampling\n",
      "    * Pick certain areas (e.g. a geographical block) randomly and then try and sample everyone in that block\n",
      "* Snowball Sampling\n",
      "    * Way to collect sample from network. Start with number of seeds (nodes) and then sample their connections. Can work well for hard to reach populations (e.g. drug users); if you know a node is a drug user then maybe more likely his connections are as well. You maybe finding the more important nodes faster this way (they have more connections). Maybe giving you a better understanding of certain regions of a network, but still maybe missing certain regions.\n",
      "* Absolute vs. Relative\n",
      "    * How big should it be?\n",
      "    * In simlpe random sampling, which matters most: relative or absolute sample size?\n",
      "        * Absolute matters way more than relative (assuming sample done well)\n",
      "        * This is because the variance in inversely related to the size\n",
      "            * $\\frac{\\sigma^2}{n}$ = Variance of Sample\n",
      "        * A good example is a bowl of soup - if it is well mixed and homogenous - you only need 1 spoonful to test it regardless of the size"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#BIAS\n",
      "* The bias of an estimator is how far off it is on average. $bias(\\hat{\\theta}) = E(\\hat{\\theta}) - \\theta$\n",
      "* Why not just subtract off bias?\n",
      "    * We don't know $\\theta$ - the bias is unknown\n",
      "    * Can estimate the bias using bootstrap, and then subtract the estimated bias\n",
      "        * This could also make things worse because of the bias-variance tradeoff: $MSE(\\hat{\\theta}) = Var(\\hat{\\theta}) + bias^2(\\hat{\\theta})$\n",
      "            * http://scott.fortmann-roe.com/docs/BiasVariance.html\n",
      "        * MSE = mean square error = average of the squares of the errors. Probably most used metric of fit\n",
      "        * If by adding a little bit of bias, might decrease variance a lot which would be good.\n",
      "* If you take sqrt of sample variance (divdes by N-1), this standard deviation is NOT unbiased\n",
      "* The more parameters you have for fixed data, the more variance and less bias you tend to get\n",
      "* Basu's elephant - estimate total weight of 50 elephants; take 1 avg. looking elephant's weight and multiply by 50; this is biased\n",
      "    * Horvitz-Thompson Estimator would be unbiased. Says the total weight = (weight / probability of being in sample) summed over the sample of elephants\n",
      "* Overall idea: don't fixate too  much of bias; also need to think about variance"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Fisher Weighting\n",
      "* How do we combine independent, unbiased estimators for a parameter into one estimator? E.g. combining election poll results\n",
      "    * Take average - this doesn't account for sample size or reliability of poll\n",
      "    * Better way is to put more weight on things with lower std error (more reliable)\n",
      "        * Optimal thing to do is inversely proportional to variance (optimal meaning minimizing MSE)\n",
      "        * Thus weight = 1 / Variance of estimator and then your overall estimator is  weight*estimator summed over all estimators\n",
      "    * May have to use other weighting based on context; for example, with election polls would also want to weight more recent polls by more"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}